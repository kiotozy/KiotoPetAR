import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.160.1/build/three.module.js';
import { GLTFLoader } from 'https://cdn.jsdelivr.net/npm/three@0.160.1/examples/jsm/loaders/GLTFLoader.js';
import { ARButton } from 'https://cdn.jsdelivr.net/npm/three@0.160.1/examples/jsm/webxr/ARButton.js';

let camera, scene, renderer, model, mixer, clock;
let currentAudio = null; // Para controlar o Ã¡udio atual e evitar sobreposiÃ§Ãµes

// ReferÃªncias aos elementos do DOM
const canvas = document.getElementById('ar-canvas');
const startARButton = document.getElementById('start-ar');
const micButton = document.getElementById('mic-button');

initScene(); // Inicializa a cena (cÃ¢mera, renderer, luzes)
loadModel(); // Carrega o modelo GLB
setupMic(); // Configura o botÃ£o do microfone

// O ARButton deve ser criado e adicionado ao body *apÃ³s* a inicializaÃ§Ã£o do renderer
// O ARButton irÃ¡ gerenciar o ciclo de vida da sessÃ£o AR e o loop de renderizaÃ§Ã£o XR.
// Portanto, a funÃ§Ã£o animate() que vocÃª tinha anteriormente serÃ¡ substituÃ­da
// pelo loop de animaÃ§Ã£o gerado pelo THREE.WebXRManager.
startARButton.addEventListener('click', () => {
    document.body.appendChild(ARButton.createButton(renderer));
    startARButton.style.display = 'none'; // Esconde o botÃ£o apÃ³s clicar
});

function initScene() {
    scene = new THREE.Scene();
    camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.01, 20);

    renderer = new THREE.WebGLRenderer({ canvas, antialias: true, alpha: true });
    renderer.setPixelRatio(window.devicePixelRatio);
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.xr.enabled = true; // Habilita o mÃ³dulo WebXR

    clock = new THREE.Clock(); // Inicializa o clock aqui

    const light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1);
    light.position.set(0.5, 1, 0.25);
    scene.add(light);

    // Redimensionamento da janela
    window.addEventListener('resize', onWindowResize);
}

function onWindowResize() {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
}

function loadModel() {
    const loader = new GLTFLoader();
    loader.load('kioto.glb', (gltf) => {
        model = gltf.scene;
        // Posicione o modelo em um local razoÃ¡vel para a cena AR
        // Em AR, o modelo aparecerÃ¡ onde vocÃª apontar a cÃ¢mera inicialmente
        // Mas para uma visualizaÃ§Ã£o inicial sem AR, ele precisa de uma posiÃ§Ã£o.
        model.position.set(0, 0, -2); // Exemplo: 2 metros Ã  frente da cÃ¢mera
        scene.add(model);

        if (gltf.animations && gltf.animations.length > 0) {
            mixer = new THREE.AnimationMixer(model);
            const action = mixer.clipAction(gltf.animations[0]);
            action.play();
            console.log("AnimaÃ§Ã£o carregada e iniciada.");
        } else {
            console.warn("Nenhuma animaÃ§Ã£o encontrada no arquivo GLB.");
        }
    }, undefined, (error) => {
        console.error('Erro ao carregar o modelo GLB:', error);
    });
}

// A funÃ§Ã£o animate() Ã© chamada automaticamente pelo renderer.setAnimationLoop
// quando uma sessÃ£o XR estÃ¡ ativa.
renderer.setAnimationLoop(() => {
    if (mixer) {
        mixer.update(clock.getDelta());
    }
    renderer.render(scene, camera);
});

function setupMic() {
    micButton.addEventListener('click', () => {
        startRecognition();
        micButton.textContent = 'Ouvindo...'; // Feedback visual
        micButton.disabled = true; // Desabilita o botÃ£o enquanto ouve
    });
}

function startRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
        alert('Reconhecimento de voz nÃ£o suportado neste navegador.');
        micButton.textContent = 'ðŸŽ¤';
        micButton.disabled = false;
        return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = 'pt-BR';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    recognition.start();

    recognition.onresult = (event) => {
        const command = event.results[0][0].transcript.toLowerCase();
        console.log('Comando detectado:', command);
        handleCommand(command);
        micButton.textContent = 'ðŸŽ¤'; // Volta ao Ã­cone padrÃ£o
        micButton.disabled = false; // Reabilita o botÃ£o
    };

    recognition.onerror = (event) => {
        console.error('Erro no reconhecimento de voz:', event.error);
        alert('Ocorreu um erro no reconhecimento de voz. Tente novamente.');
        micButton.textContent = 'ðŸŽ¤';
        micButton.disabled = false;
    };

    recognition.onend = () => {
        console.log('Reconhecimento de voz encerrado.');
        // O botÃ£o jÃ¡ foi reabilitado em onresult ou onerror, mas garantimos aqui tambÃ©m.
        if (micButton.disabled) {
            micButton.textContent = 'ðŸŽ¤';
            micButton.disabled = false;
        }
    };
}

function handleCommand(command) {
    if (command.includes('danÃ§ar') && mixer) {
        // Reinicia a animaÃ§Ã£o para a primeira animaÃ§Ã£o do GLB
        // Se vocÃª tiver vÃ¡rias animaÃ§Ãµes, precisaria de uma lÃ³gica mais elaborada para selecionar.
        const action = mixer.clipAction(model.animations[0]);
        action.reset().play(); // Reseta e toca a animaÃ§Ã£o
        console.log("Comando 'danÃ§ar' detectado. AnimaÃ§Ã£o iniciada.");
        playAudio('dancar.mp3'); // Assumindo que vocÃª tem um Ã¡udio para "danÃ§ar"
    } else if (command.includes('parar') && mixer) {
        mixer.stopAllAction(); // Para todas as animaÃ§Ãµes
        console.log("Comando 'parar' detectado. AnimaÃ§Ã£o parada.");
        playAudio('parar.mp3'); // Assumindo que vocÃª tem um Ã¡udio para "parar"
    } else if (command.includes('comando') || command.includes('comandos')) {
        playAudio('comandos.mp3');
        console.log("Comando 'comandos' detectado. Ãudio 'comandos.mp3' reproduzido.");
    } else {
        playAudio('nao_entendi.mp3'); // Ãudio para comando nÃ£o reconhecido
        console.log("Comando nÃ£o reconhecido.");
    }
}

function playAudio(file) {
    // Para evitar sobreposiÃ§Ãµes, pare o Ã¡udio anterior se houver
    if (currentAudio) {
        currentAudio.pause();
        currentAudio.currentTime = 0;
    }
    currentAudio = new Audio(file);
    currentAudio.play().catch(e => console.error("Erro ao reproduzir Ã¡udio:", e));
}
