import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.160.1/build/three.module.js';
import { GLTFLoader } from 'https://cdn.jsdelivr.net/npm/three@0.160.1/examples/jsm/loaders/GLTFLoader.js';
import { ARButton } from 'https://cdn.jsdelivr.net/npm/three@0.160.1/examples/jsm/webxr/ARButton.js';

let camera, scene, renderer;
let model, mixer, clock;
let currentAudio = null; // Para gerenciar a reprodu√ß√£o de √°udios
let hitTestSource = null; // Para posicionamento em AR
let hitTestSourceInitialized = false; // Flag para indicar se o hit test est√° pronto
let modelPlacedInAR = false; // Flag para controlar se o modelo j√° foi posicionado no AR

// Elementos do DOM
const canvas = document.getElementById('ar-canvas');
const micButton = document.getElementById('mic-button');

// Mapeamento de comandos de voz para arquivos de √°udio
// Baseado nos nomes de arquivo que voc√™ forneceu na imagem.
const audioCommands = {
    'oi': 'ola.mp3',
    'ol√°': 'ola.mp3', // Sin√¥nimo para 'ol√°'
    'bom dia': 'bom_dia.mp3',
    'boa tarde': 'boa_tarde.mp3',
    'boa noite': 'boa_noite.mp3',
    'qual seu nome': 'qual_seu_nome.mp3',
    'quer ser meu': 'quer_ser_meu.mp3',
    'comandos': 'comandos.mp3',
    'comando': 'comandos.mp3', // Sin√¥nimo para 'comando'
};

init();
setupMic();

async function init() {
    scene = new THREE.Scene();
    camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.01, 20);
    clock = new THREE.Clock();

    renderer = new THREE.WebGLRenderer({ canvas: canvas, antialias: true, alpha: true });
    renderer.setPixelRatio(window.devicePixelRatio);
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.xr.enabled = true; // Habilita o m√≥dulo WebXR

    // Adiciona uma luz ambiente
    const light = new THREE.HemisphereLight(0xffffff, 0xbbbbff, 1);
    light.position.set(0.5, 1, 0.25);
    scene.add(light);

    // O reticle √© um c√≠rculo que ajuda o usu√°rio a posicionar o objeto no ambiente AR
    const reticle = new THREE.Mesh(
        new THREE.RingGeometry(0.15, 0.2, 32).rotateX(-Math.PI / 2),
        new THREE.MeshBasicMaterial({ color: 0xffffff, opacity: 0.5, transparent: true })
    );
    reticle.matrixAutoUpdate = false; // Permite controle manual da posi√ß√£o
    reticle.visible = false;
    scene.add(reticle);

    // Carrega o modelo GLB
    await loadModel();

    // Tenta iniciar a sess√£o AR automaticamente
    try {
        // Verifica se WebXR √© suportado e se o modo 'immersive-ar' est√° dispon√≠vel
        const isARSupported = await navigator.xr.isSessionSupported('immersive-ar');
        if (!isARSupported) {
            throw new Error("Sess√£o AR imersiva n√£o suportada neste dispositivo/navegador.");
        }

        const session = await navigator.xr.requestSession('immersive-ar', {
            requiredFeatures: ['hit-test', 'dom-overlay'],
            domOverlay: { root: document.body }
        });
        renderer.xr.setSession(session);
        console.log("Sess√£o AR iniciada automaticamente.");

        // Adiciona um listener para quando a sess√£o AR √© finalizada
        session.addEventListener('end', () => {
            console.log('Sess√£o AR finalizada.');
            // Se precisar resetar o estado ou voltar para um modo 3D padr√£o:
            modelPlacedInAR = false;
            // Opcional: remover o modelo da cena ou reposicion√°-lo
            if (model && model.parent) {
                scene.remove(model);
            }
        });

        // Configura o hit test para posicionar o modelo no ambiente AR
        session.requestReferenceSpace('viewer').then((referenceSpace) => {
            session.requestHitTestSource({ space: referenceSpace }).then((source) => {
                hitTestSource = source;
                hitTestSourceInitialized = true;
                console.log("Hit test source inicializado.");
            });
        });

        // Loop de renderiza√ß√£o para AR
        renderer.setAnimationLoop((timestamp, frame) => {
            if (frame && hitTestSourceInitialized && !modelPlacedInAR) {
                const referenceSpace = renderer.xr.getReferenceSpace();
                const hitTestResults = frame.getHitTestResults(hitTestSource);

                if (hitTestResults.length) {
                    const hit = hitTestResults[0];
                    const pose = hit.getPose(referenceSpace);

                    reticle.matrix.copy(pose.transform.matrix);
                    reticle.visible = true;

                    // Posiciona o modelo automaticamente quando uma superf√≠cie √© encontrada
                    if (!modelPlacedInAR && model) {
                        model.position.setFromMatrixPosition(reticle.matrix);
                        model.scale.set(0.5, 0.5, 0.5); // Ajuste a escala conforme necess√°rio
                        scene.add(model);
                        modelPlacedInAR = true;
                        reticle.visible = false; // Esconde o reticle depois de posicionar

                        if (mixer && model.animations.length > 0) {
                            mixer.clipAction(model.animations[0]).play(); // Inicia a anima√ß√£o
                            console.log("Modelo posicionado e anima√ß√£o iniciada em AR.");
                        } else {
                            console.warn("Anima√ß√µes n√£o dispon√≠veis ou mixer n√£o inicializado.");
                        }
                    }
                } else {
                    reticle.visible = false;
                }
            }

            if (mixer) {
                mixer.update(clock.getDelta());
            }
            renderer.render(scene, camera);
        });

    } catch (e) {
        console.error("WebXR n√£o suportado ou sess√£o AR n√£o iniciada:", e);
        alert("Seu navegador n√£o suporta Realidade Aumentada ou a sess√£o n√£o p√¥de ser iniciada automaticamente. Tentando exibir em 3D normal.");
        // Se AR n√£o for suportado, exiba o modelo em um modo 3D normal
        scene.add(model);
        model.position.set(0, 0, -3); // Posiciona o modelo √† frente da c√¢mera para visualiza√ß√£o padr√£o
        model.scale.set(1, 1, 1); // Escala padr√£o
        if (mixer && model.animations.length > 0) {
            const action = mixer.clipAction(model.animations[0]);
            action.play();
            console.log("Anima√ß√£o iniciada em modo 3D normal.");
        } else {
            console.warn("Nenhuma anima√ß√£o para reproduzir em modo 3D normal.");
        }
        // Configura um loop de anima√ß√£o b√°sico para o modo 3D
        renderer.setAnimationLoop(() => {
            if (mixer) mixer.update(clock.getDelta());
            renderer.render(scene, camera);
        });
    }

    // Listener para redimensionamento da janela
    window.addEventListener('resize', onWindowResize);
}

function onWindowResize() {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
}

async function loadModel() {
    return new Promise((resolve, reject) => {
        const loader = new GLTFLoader();
        loader.load('kioto.glb', (gltf) => {
            model = gltf.scene;
            // O mixer √© inicializado aqui, mas a anima√ß√£o s√≥ ser√° iniciada quando o modelo for adicionado √† cena AR
            if (gltf.animations && gltf.animations.length > 0) {
                mixer = new THREE.AnimationMixer(model);
                // N√£o inicia a anima√ß√£o aqui, pois ela ser√° iniciada ap√≥s o posicionamento em AR.
                model.animations = gltf.animations; // Armazena as anima√ß√µes no modelo para f√°cil acesso
                console.log("Modelo GLB carregado com anima√ß√µes. Anima√ß√£o aguardando posicionamento em AR.");
            } else {
                console.warn("Nenhuma anima√ß√£o encontrada no arquivo GLB.");
            }
            resolve();
        }, undefined, (error) => {
            console.error('Erro ao carregar o modelo GLB:', error);
            reject(error);
        });
    });
}

function setupMic() {
    micButton.addEventListener('click', () => {
        startRecognition();
        micButton.textContent = 'Ouvindo...'; // Feedback visual
        micButton.disabled = true; // Desabilita o bot√£o enquanto ouve
    });
}

function startRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
        alert('Reconhecimento de voz n√£o suportado neste navegador. Tente usar Chrome ou Edge.');
        micButton.textContent = 'üé§';
        micButton.disabled = false;
        return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = 'pt-BR';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    recognition.start();

    recognition.onresult = (event) => {
        const command = event.results[0][0].transcript.toLowerCase();
        console.log('Comando de voz detectado:', command);
        handleCommand(command);
    };

    recognition.onerror = (event) => {
        console.error('Erro no reconhecimento de voz:', event.error);
        alert('Ocorreu um erro no reconhecimento de voz. Por favor, verifique as permiss√µes do microfone e tente novamente.');
        micButton.textContent = 'üé§';
        micButton.disabled = false;
    };

    recognition.onend = () => {
        console.log('Reconhecimento de voz encerrado.');
        micButton.textContent = 'üé§'; // Volta ao √≠cone padr√£o
        micButton.disabled = false; // Reabilita o bot√£o
    };
}

function handleCommand(command) {
    // Comando para iniciar a anima√ß√£o (primeira anima√ß√£o do GLB)
    if (command.includes('dan√ßar') && mixer && model.animations && model.animations.length > 0) {
        const action = mixer.clipAction(model.animations[0]);
        action.reset().play(); // Reinicia e reproduz a primeira anima√ß√£o
        console.log("Comando 'dan√ßar': Anima√ß√£o iniciada.");
    }
    // Comando para parar a anima√ß√£o
    else if (command.includes('parar') && mixer) {
        mixer.stopAllAction(); // Para todas as anima√ß√µes
        console.log("Comando 'parar': Anima√ß√£o parada.");
    }
    // Comandos de √°udio gerais (usando o mapeamento audioCommands)
    else {
        let foundMatch = false;
        // Itera sobre as chaves do audioCommands para encontrar uma correspond√™ncia parcial
        for (const key in audioCommands) {
            // Verifica se o comando falado cont√©m a chave.
            // A ordem das chaves em audioCommands pode influenciar se houver sobreposi√ß√£o.
            // Para "qual seu nome" ser preferido a "nome", "qual seu nome" deve vir antes ou a verifica√ß√£o ser mais espec√≠fica.
            if (command.includes(key)) {
                playAudio(audioCommands[key]);
                console.log(`Comando '${command}' corresponde a '${key}': √Åudio '${audioCommands[key]}' reproduzido.`);
                foundMatch = true;
                break; // Sai do loop assim que encontrar o primeiro comando
            }
        }

        // Caso o comando n√£o seja reconhecido ou n√£o tenha a√ß√£o espec√≠fica
        if (!foundMatch) {
            playAudio('nao_entendi.mp3'); // √Åudio padr√£o para "n√£o entendi"
            console.log(`Comando '${command}' n√£o reconhecido ou sem a√ß√£o associada.`);
        }
    }
}

function playAudio(file) {
    // Para evitar sobreposi√ß√µes, pare o √°udio anterior se houver
    if (currentAudio) {
        currentAudio.pause();
        currentAudio.currentTime = 0;
    }
    currentAudio = new Audio(file);
    currentAudio.play().catch(e => console.error("Erro ao reproduzir √°udio:", e));
}
