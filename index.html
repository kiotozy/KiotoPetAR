<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Kioto AR</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/aframe-extras@6.1.1/dist/aframe-extras.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/ar.js@3.4.2/aframe/build/aframe-ar.min.js"></script>
    <style>
      body {
        margin: 0;
        overflow: hidden;
      }
      #btns {
        position: fixed;
        bottom: 20px;
        width: 100%;
        text-align: center;
        z-index: 999;
      }
      button {
        font-size: 16px;
        padding: 12px 20px;
        margin: 5px;
        border: none;
        border-radius: 6px;
        background: #00aaff;
        color: white;
        font-weight: bold;
      }
    </style>
  </head>
  <body>
    <div id="btns">
      <button id="mic">ðŸŽ¤ Falar</button>
      <button onclick="activateAR()">Ativar AR</button>
    </div>

    <a-scene
      id="scene"
      background="color: #ffffff"
      embedded
      vr-mode-ui="enabled: false"
      renderer="antialias: true"
    >
      <a-assets>
        <a-asset-item id="model" src="kioto.glb"></a-asset-item>
      </a-assets>

      <a-entity
        id="character"
        gltf-model="#model"
        position="0 0 -1.5"
        rotation="0 0 0"
        animation-mixer
        gesture-detector
        scale="1 1 1"
      ></a-entity>

      <a-camera position="0 1.6 0"></a-camera>
    </a-scene>

    <script>
      let mixer, character, currentAction;

      AFRAME.registerComponent("gesture-detector", {
        init: function () {
          this.el.sceneEl.addEventListener("mousedown", this.startDrag.bind(this));
          this.el.sceneEl.addEventListener("mouseup", this.stopDrag.bind(this));
          this.el.sceneEl.addEventListener("mousemove", this.onDrag.bind(this));
          this.dragging = false;
        },
        startDrag: function (event) {
          this.dragging = true;
          this.lastX = event.screenX;
        },
        stopDrag: function () {
          this.dragging = false;
        },
        onDrag: function (event) {
          if (!this.dragging) return;
          let deltaX = event.screenX - this.lastX;
          this.lastX = event.screenX;
          const rotation = this.el.getAttribute("rotation");
          rotation.y += deltaX * 0.5;
          this.el.setAttribute("rotation", rotation);
        },
      });

      document.addEventListener("DOMContentLoaded", () => {
        character = document.querySelector("#character");
        character.addEventListener("model-loaded", () => {
          const model = character.getObject3D("mesh");
          mixer = new THREE.AnimationMixer(model);
          model.animations = character.components["gltf-model"].model.animations;
          if (model.animations.length > 0) {
            currentAction = mixer.clipAction(model.animations[0]);
            currentAction.play();
          }
        });
      });

      function activateAR() {
        document.querySelector("a-scene").setAttribute("arjs", "sourceType: webcam; debugUIEnabled: false");
        document.body.style.backgroundColor = "transparent";
      }

      function speak(text) {
        new Audio(text).play();
      }

      const commands = {
        olÃ¡: "ola.mp3",
        "bom dia": "bom_dia.mp3",
        "boa tarde": "boa_tarde.mp3",
        "boa noite": "boa_noite.mp3",
        "qual seu nome": "qual_seu_nome.mp3",
        "quer ser meu amigo": "quer_ser_meu_amigo.mp3",
        "nao entendi": "nao_entendi.mp3",
        danÃ§ar: () => {
          if (currentAction) currentAction.play();
        },
        parar: () => {
          if (currentAction) currentAction.stop();
        },
      };

      document.getElementById("mic").addEventListener("click", () => {
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = "pt-BR";
        recognition.onresult = (event) => {
          const said = event.results[0][0].transcript.toLowerCase();
          console.log("Comando:", said);
          const cmd = Object.keys(commands).find((c) => said.includes(c));
          if (cmd) {
            const action = commands[cmd];
            if (typeof action === "function") {
              action();
            } else {
              speak(action);
            }
          } else {
            speak("nao_entendi.mp3");
          }
        };
        recognition.start();
      });

      AFRAME.registerComponent("animation-mixer", {
        tick: function (time, delta) {
          if (mixer) mixer.update(delta / 1000);
        },
      });
    </script>
  </body>
</html>
