<!DOCTYPE html>
<html lang="pt-br">
<head>
  <meta charset="utf-8">
  <title>Kioto Pet AR - IA</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/aframe-extras@6.1.1/dist/aframe-extras.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/aframe-gesture-detector@3.3.0/dist/aframe-gesture-detector.min.js"></script>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      font-family: sans-serif;
    }
    #buttons {
      position: fixed;
      bottom: 20px;
      left: 0;
      width: 100%;
      display: flex;
      justify-content: center;
      gap: 10px;
      z-index: 1000;
    }
    button {
      padding: 12px 20px;
      font-size: 16px;
      color: white;
      border: none;
      border-radius: 8px;
      cursor: pointer;
    }
    #micButton {
      background-color: #03a9f4;
    }
    #micButton.listening {
      background-color: green;
    }
    #arButton {
      background-color: #03a9f4;
    }
    a-scene {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: 1;
    }
  </style>
</head>
<body>
  <div id="buttons">
    <button id="micButton">🎤 Falar</button>
    <button id="arButton">Ativar AR</button>
  </div>

  <a-scene id="scene" embedded xr-mode-ui="enabled: false"
    renderer="antialias: true" gesture-detector>

    <a-assets>
      <a-asset-item id="model" src="kioto.glb"></a-asset-item>
    </a-assets>

    <a-entity
      id="glb"
      gltf-model="#model"
      animation-mixer
      rotation="0 0 0"
      position="0 0 -2"
      scale="1 1 1"
      gesture-detector
    ></a-entity>

    <a-plane id="ground" position="0 0 -4" rotation="-90 0 0" width="10" height="10" color="#7BC8A4"></a-plane>
    <a-sky id="sky" color="#ECECEC"></a-sky>
    
    <a-entity camera position="0 1.6 0" look-controls="enabled: true"></a-entity>
  </a-scene>

  <script>
    const modelEntity = document.getElementById('glb');
    const arButton = document.getElementById('arButton');
    const scene = document.querySelector('a-scene');
    const ground = document.getElementById('ground');
    const sky = document.getElementById('sky');
    const micButton = document.getElementById('micButton');

    scene.setAttribute('vr-mode-ui', 'enabled: false');
    scene.setAttribute('ar-mode-ui', 'enabled: false');

    window.onload = function() {
        modelEntity.setAttribute('animation-mixer', '');
    };

    AFRAME.registerComponent('gesture-detector', {
      init: function () {
        this.el.sceneEl.addEventListener('onefingermove', (event) => {
          const rotation = this.el.getAttribute('rotation');
          this.el.setAttribute('rotation', {
            x: rotation.x,
            y: rotation.y + event.detail.positionChange.x * 2,
            z: rotation.z
          });
        });
      }
    });

    arButton.addEventListener('click', () => {
      scene.enterAR();
    });

    scene.addEventListener('enter-vr', function () {
      if (this.is('ar-mode')) {
        ground.setAttribute('visible', 'false');
        sky.setAttribute('visible', 'false');
      }
    });
    
    let recognition;
    let isListening = false;
    let isPermanentlyListening = false;
    let isSpeaking = false;

    // AQUI ESTÁ O URL DO SEU SERVIDOR, JÁ CORRIGIDO
    const PROXY_SERVER_URL = 'https://a5952083-3c46-4fb2-9efd-4dcc842add19-00-3cqsrhmbwh2nz.riker.replit.dev/ask-gemini';

    function startRecognition() {
      if (recognition && !isListening && !isSpeaking) {
        recognition.start();
      }
    }

    function speakText(text) {
        if (window.speechSynthesis) {
            isSpeaking = true;
            const utterThis = new SpeechSynthesisUtterance(text);
            utterThis.lang = 'pt-BR';
            
            utterThis.onend = () => {
                isSpeaking = false;
                if (isPermanentlyListening) {
                    setTimeout(startRecognition, 1000); // Reinicia a escuta após a fala
                }
            };
            
            window.speechSynthesis.speak(utterThis);
        } else {
            console.error('API de conversão de texto em fala não suportada.');
        }
    }

    async function askGemini(prompt) {
        try {
            const response = await fetch(PROXY_SERVER_URL, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ prompt: prompt })
            });
            const data = await response.json();
            if (response.ok) {
                speakText(data.text);
            } else {
                speakText('Desculpe, ocorreu um erro ao se comunicar com a inteligência artificial.');
            }
        } catch (error) {
            console.error('Erro ao chamar a API do Gemini:', error);
            speakText('Desculpe, não consegui me conectar à inteligência artificial.');
        }
    }

    if ('webkitSpeechRecognition' in window) {
      recognition = new webkitSpeechRecognition();
      recognition.lang = 'pt-BR';
      recognition.continuous = false;
      recognition.interimResults = false;

      micButton.addEventListener('click', () => {
        if (!isPermanentlyListening) {
          isPermanentlyListening = true;
          startRecognition();
        } else {
          isPermanentlyListening = false;
          recognition.stop();
        }
      });

      recognition.onstart = () => {
        isListening = true;
        micButton.classList.add('listening');
        micButton.textContent = '🎤 Ouvindo...';
      };

      recognition.onend = () => {
        isListening = false;
        if (!isSpeaking && isPermanentlyListening) {
          setTimeout(startRecognition, 1000); 
        } else if (!isPermanentlyListening) {
          micButton.classList.remove('listening');
          micButton.textContent = '🎤 Falar';
        }
      };

      recognition.onresult = (event) => {
        const comando = event.results[0][0].transcript.toLowerCase();
        console.log('Comando de voz:', comando);
        
        recognition.stop();
        askGemini(comando);
      };

      recognition.onerror = (event) => {
        console.error('Erro no reconhecimento de voz:', event.error);
        if (event.error !== 'no-speech') {
            isPermanentlyListening = false;
            micButton.classList.remove('listening');
            micButton.textContent = '🎤 Erro';
        }
      };

    }
  </script>
</body>
</html>
